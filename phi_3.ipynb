{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8509aac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import fitz\n",
    "import docx2txt\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "371268c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "520b5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(file):\n",
    "    fn = file.name.lower()\n",
    "    try:\n",
    "        if fn.endswith(\".pdf\"):\n",
    "            pdf_file = fitz.open(fn)\n",
    "            text = \"\"\n",
    "            for page in pdf_file:\n",
    "                text += page.get_text()\n",
    "            return text\n",
    "        elif fn.endswith(\".docx\"):\n",
    "            return docx2txt.process(fn)\n",
    "        elif fn.endswith(\".txt\"):\n",
    "            with open(fn, \"r\", encoding=\"utf-8\") as f:\n",
    "                return f.read()\n",
    "        else:\n",
    "            return \"Unsupported file format. Please upload PDF, DOCX, or TXT.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading file: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d60392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_mcqs(content, n=3, level=\"Easy\"):\n",
    "#     prompt = f\"\"\"\n",
    "# Generate {n} single-choice MCQs based on the text below.\n",
    "# Difficulty level: {level}\n",
    "\n",
    "# Instructions:\n",
    "# - Each question should have exactly 4 options (a–d).\n",
    "# - Only one option should be correct.\n",
    "# - Provide answers and short explanations.\n",
    "# - Don't provide anything off topic from the content given by the user \n",
    "# - Use this format strictly:\n",
    "\n",
    "# Q1. <question>\n",
    "# a) <option1>\n",
    "# b) <option2>\n",
    "# c) <option3>\n",
    "# d) <option4>\n",
    "# Answer: <correct option letter>\n",
    "# Explanation: <short explanation>\n",
    "\n",
    "# Text:\n",
    "# ---\n",
    "# {content}\n",
    "# ---\n",
    "# \"\"\"\n",
    "#     response = requests.post(\n",
    "#         \"http://localhost:11434/api/generate\",\n",
    "#         json={\"model\": \"phi3\", \"prompt\": prompt, \"stream\": False}\n",
    "#     )\n",
    "#     return response.json().get(\"response\", \"\").strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3fa40a",
   "metadata": {},
   "source": [
    "Single choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "275b0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_choice(content, n=3, level=\"Easy\"):\n",
    "    prompt = f\"\"\"\n",
    "Generate {n} single-choice MCQs based on the text below.\n",
    "Difficulty level: {level}\n",
    "\n",
    "Instructions:\n",
    "- Each question should have exactly 4 options (a–d).\n",
    "- Only one option should be correct.\n",
    "- Provide answers and short explanations.\n",
    "- Stay strictly within the topic of the text.\n",
    "- Use this format strictly:\n",
    "\n",
    "Q1. <question>\n",
    "a) <option1>\n",
    "b) <option2>\n",
    "c) <option3>\n",
    "d) <option4>\n",
    "Answer: <correct option letter>\n",
    "Explanation: <short explanation>\n",
    "\n",
    "Text:\n",
    "---\n",
    "{content}\n",
    "---\n",
    "\"\"\"\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\"model\": \"phi3\", \"prompt\": prompt, \"stream\": False}\n",
    "    )\n",
    "    return response.json().get(\"response\", \"\").strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f1b4b2",
   "metadata": {},
   "source": [
    "Multi choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef080659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multi_choice(content, n=3, level=\"Medium\"):\n",
    "    prompt = f\"\"\"\n",
    "Generate {n} multiple-choice questions based on the text below.\n",
    "Difficulty level: {level}\n",
    "\n",
    "Instructions:\n",
    "- Each question should have 4 options (a–d).\n",
    "- Two or more options can be correct.\n",
    "- List all correct options (e.g., \"Answer: a, c\").\n",
    "- Provide a short explanation for why those are correct.\n",
    "- Stay strictly within the topic of the text.\n",
    "\n",
    "Format strictly:\n",
    "\n",
    "Q1. <question>\n",
    "a) <option1>\n",
    "b) <option2>\n",
    "c) <option3>\n",
    "d) <option4>\n",
    "Answer: <correct option letters>\n",
    "Explanation: <short explanation>\n",
    "\n",
    "Text:\n",
    "---\n",
    "{content}\n",
    "---\n",
    "\"\"\"\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\"model\": \"phi3\", \"prompt\": prompt, \"stream\": False}\n",
    "    )\n",
    "    return response.json().get(\"response\", \"\").strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35849df8",
   "metadata": {},
   "source": [
    "True /False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3844769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_true_false(content, n=5, level=\"Easy\"):\n",
    "    prompt = f\"\"\"\n",
    "Generate {n} True or False questions based on the text below.\n",
    "Difficulty level: {level}\n",
    "\n",
    "Instructions:\n",
    "- Write concise factual statements that can be clearly True or False.\n",
    "- Provide the correct answer and a short explanation.\n",
    "- Stay relevant to the text only.\n",
    "- Stay strictly within the topic of the text.\n",
    "\n",
    "Format strictly:\n",
    "\n",
    "Q1. <statement>\n",
    "a) True\n",
    "b) False\n",
    "Answer: True or False\n",
    "Explanation: <short explanation>\n",
    "\n",
    "Text:\n",
    "---\n",
    "{content}\n",
    "---\n",
    "\"\"\"\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\"model\": \"phi3\", \"prompt\": prompt, \"stream\": False}\n",
    "    )\n",
    "    return response.json().get(\"response\", \"\").strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa7ae34",
   "metadata": {},
   "source": [
    "Fill in the Blannks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d481f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fill_blanks(content, n=5, level=\"Medium\"):\n",
    "    prompt = f\"\"\"\n",
    "You are an educational content expert. Generate {n} meaningful fill-in-the-blank questions based on the text below.\n",
    "Focus on **concepts, definitions, and key terms**, not literal code symbols or parentheses.\n",
    "\n",
    "Instructions:\n",
    "1. Select a key word or phrase that captures the main idea of the sentence.\n",
    "2. Replace the key word or phrase with a blank (____).\n",
    "3. Provide a clear, concise answer (the missing word or phrase).\n",
    "4. Include a short explanation of why this is the correct answer.\n",
    "5. Do NOT include underscores, parentheses, or code syntax in the blanks unless the concept itself is code-related.\n",
    "6. Stay strictly within the topic of the text.\n",
    "Format strictly:\n",
    "Q1. <sentence with blank>\n",
    "Answer: <correct word or phrase>\n",
    "Explanation: <short explanation>\n",
    "\n",
    "Example:\n",
    "\n",
    "Q1. ____ is a high-level programming language.\n",
    "Answer: Python\n",
    "Explanation: Python is the programming language being described.\n",
    "\n",
    "Text:\n",
    "---\n",
    "{content}\n",
    "---\n",
    "\"\"\"\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\"model\": \"phi3\", \"prompt\": prompt, \"stream\": False}\n",
    "    )\n",
    "    return response.json().get(\"response\", \"\").strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1a3b4",
   "metadata": {},
   "source": [
    "Subjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a2f2bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subjective(content, n=3, level=\"Hard\"):\n",
    "    prompt = f\"\"\"\n",
    "Generate {n} subjective (open-ended) questions based on the text below.\n",
    "Difficulty level: {level}\n",
    "\n",
    "Instructions:\n",
    "- Each question should test understanding, analysis, or reasoning.\n",
    "- Do NOT include options.\n",
    "- Provide a short ideal answer or key points expected in the answer.\n",
    "- Stay within the topic context.\n",
    "\n",
    "Format strictly:\n",
    "\n",
    "Q1. <question>\n",
    "Ideal Answer: <concise key answer>\n",
    "\n",
    "Text:\n",
    "---\n",
    "{content}\n",
    "---\n",
    "\"\"\"\n",
    "    response = requests.post(\n",
    "        \"http://localhost:11434/api/generate\",\n",
    "        json={\"model\": \"phi3\", \"prompt\": prompt, \"stream\": False}\n",
    "    )\n",
    "    return response.json().get(\"response\", \"\").strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c765bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_mcqs_to_file(mcq_text, fmt):\n",
    "#     questions = []\n",
    "#     for block in mcq_text.split(\"Q\"):\n",
    "#         block = block.strip()\n",
    "#         if not block or not block[0].isdigit():\n",
    "#             continue\n",
    "#         lines = block.split(\"\\n\")\n",
    "#         q_text = lines[0][2:].strip()\n",
    "#         options = [l.strip()[3:] for l in lines[1:5] if l.strip().startswith((\"a)\", \"b)\", \"c)\", \"d)\"))]\n",
    "#         answer = next((l.split(\":\")[1].strip() for l in lines if l.startswith(\"Answer:\")), \"\")\n",
    "#         explanation = next((l.split(\":\")[1].strip() for l in lines if l.startswith(\"Explanation:\")), \"\")\n",
    "#         questions.append({\n",
    "#             \"Question\": q_text,\n",
    "#             \"Option A\": options[0] if len(options) > 0 else \"\",\n",
    "#             \"Option B\": options[1] if len(options) > 1 else \"\",\n",
    "#             \"Option C\": options[2] if len(options) > 2 else \"\",\n",
    "#             \"Option D\": options[3] if len(options) > 3 else \"\",\n",
    "            \n",
    "#         })\n",
    "\n",
    "#     if not questions:\n",
    "#         return None\n",
    "\n",
    "#     df = pd.DataFrame(questions)\n",
    "#     filename = f\"mcqs.{fmt}\"\n",
    "\n",
    "#     if fmt == \"xlsx\":\n",
    "#         df.to_excel(filename, index=False)\n",
    "#     elif fmt == \"csv\":\n",
    "#         df.to_csv(filename, index=False)\n",
    "#     elif fmt == \"json\":\n",
    "#         df.to_json(filename, orient=\"records\", indent=4)\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "#     return os.path.abspath(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35750d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "# import re\n",
    "\n",
    "# def save_questions_to_file(text, qtype, fmt=\"xlsx\"):\n",
    "#     questions = []\n",
    "\n",
    "#     # Split by Q1, Q2... pattern\n",
    "#     blocks = re.split(r\"\\n?Q\\d+[:.]?\", text)\n",
    "\n",
    "#     for block in blocks:\n",
    "#         block = block.strip()\n",
    "#         if not block:\n",
    "#             continue\n",
    "\n",
    "#         q_data = {\"Type\": qtype}\n",
    "\n",
    "#         # SINGLE / MULTI CHOICE\n",
    "#         if qtype in [\"single\", \"multi\"]:\n",
    "#             # Split lines\n",
    "#             lines = [l.strip() for l in block.split(\"\\n\") if l.strip()]\n",
    "#             if not lines:\n",
    "#                 continue\n",
    "\n",
    "#             # First line is question\n",
    "#             q_data[\"Question\"] = lines[0]\n",
    "\n",
    "#             # Options: all lines until Answer: or Explanation:\n",
    "#             options = []\n",
    "#             for l in lines[1:]:\n",
    "#                 if l.startswith(\"Answer:\") or l.startswith(\"Explanation:\"):\n",
    "#                     break\n",
    "#                 options.append(l)\n",
    "\n",
    "#             # Map options to Option A, B, C...\n",
    "#             for i, opt in enumerate(options):\n",
    "#                 q_data[f\"Option {chr(65+i)}\"] = opt\n",
    "\n",
    "#             # Answer\n",
    "#             ans_match = re.search(r\"Answer:\\s*(.*)\", block)\n",
    "#             q_data[\"Answer\"] = ans_match.group(1).strip() if ans_match else \"\"\n",
    "\n",
    "#             # Explanation\n",
    "#             exp_match = re.search(r\"Explanation:\\s*(.*)\", block)\n",
    "#             q_data[\"Explanation\"] = exp_match.group(1).strip() if exp_match else \"\"\n",
    "\n",
    "#         # TRUE/FALSE\n",
    "#         elif qtype == \"truefalse\":\n",
    "#             q_match = re.match(r\"^(.*?)Answer:\", block, re.DOTALL)\n",
    "#             q_data[\"Question\"] = q_match.group(1).strip() if q_match else block\n",
    "\n",
    "#             ans_match = re.search(r\"Answer:\\s*(True|False)\", block, re.IGNORECASE)\n",
    "#             exp_match = re.search(r\"Explanation:\\s*(.*)\", block)\n",
    "#             q_data[\"Answer\"] = ans_match.group(1).strip().capitalize() if ans_match else \"\"\n",
    "#             q_data[\"Explanation\"] = exp_match.group(1).strip() if exp_match else \"\"\n",
    "\n",
    "#         # FILL IN THE BLANKS\n",
    "#         elif qtype == \"fill\":\n",
    "#             q_match = re.match(r\"^(.*?)Answer:\", block, re.DOTALL)\n",
    "#             q_data[\"Question\"] = q_match.group(1).strip() if q_match else block\n",
    "\n",
    "#             ans_match = re.search(r\"Answer:\\s*(.*)\", block)\n",
    "#             exp_match = re.search(r\"Explanation:\\s*(.*)\", block)\n",
    "#             q_data[\"Answer\"] = ans_match.group(1).strip() if ans_match else \"\"\n",
    "#             q_data[\"Explanation\"] = exp_match.group(1).strip() if exp_match else \"\"\n",
    "\n",
    "#         # SUBJECTIVE\n",
    "#         elif qtype == \"subjective\":\n",
    "#             q_match = re.match(r\"^(.*?)Ideal Answer:\", block, re.DOTALL)\n",
    "#             q_data[\"Question\"] = q_match.group(1).strip() if q_match else block\n",
    "\n",
    "#             ans_match = re.search(r\"Ideal Answer:\\s*(.*)\", block)\n",
    "#             q_data[\"Ideal Answer\"] = ans_match.group(1).strip() if ans_match else \"\"\n",
    "\n",
    "#         questions.append(q_data)\n",
    "\n",
    "#     if not questions:\n",
    "#         return None\n",
    "\n",
    "#     df = pd.DataFrame(questions)\n",
    "#     filename = f\"questions_{qtype}.{fmt}\"\n",
    "\n",
    "#     if fmt == \"xlsx\":\n",
    "#         df.to_excel(filename, index=False)\n",
    "#     elif fmt == \"csv\":\n",
    "#         df.to_csv(filename, index=False)\n",
    "#     elif fmt == \"json\":\n",
    "#         df.to_json(filename, orient=\"records\", indent=4)\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported format. Use 'xlsx', 'csv', or 'json'.\")\n",
    "\n",
    "#     return os.path.abspath(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_and_save_mcqs(pasted_text, uploaded_file, n, level, download_format):\n",
    "#     content = pasted_text or \"\"\n",
    "#     if uploaded_file is not None:\n",
    "#         file_text = extract_file(uploaded_file)\n",
    "#         if \"Unsupported\" in file_text or \"Error\" in file_text:\n",
    "#             return file_text, None\n",
    "#         content += \"\\n\" + file_text\n",
    "\n",
    "#     if not content.strip():\n",
    "#         return \"Please provide text or upload a file.\", None\n",
    "\n",
    "#     mcq_text = generate_mcqs(content, n, level)\n",
    "#     if not mcq_text.strip():\n",
    "#         return \"No MCQs generated. Please try again.\", None\n",
    "\n",
    "    \n",
    "#     file_path = save_mcqs_to_file(mcq_text, download_format)\n",
    "#     return mcq_text.replace(\"\\n\", \"<br>\"), file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf32b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def save_questions_clean(text, qtype=\"single\", fmt=\"xlsx\"):\n",
    "    questions = []\n",
    "\n",
    "    # Split by Q1, Q2, ...\n",
    "    blocks = re.split(r\"\\n?Q\\d+[:.]?\", text)\n",
    "\n",
    "    for block in blocks:\n",
    "        block = block.strip()\n",
    "        if not block:\n",
    "            continue\n",
    "\n",
    "        q_data = {\"Type\": qtype}\n",
    "\n",
    "        if qtype in [\"single\", \"multi\"]:\n",
    "            # Find up to 4 options a-d\n",
    "            option_matches = list(re.finditer(r\"([a-dA-D])\\)\\s*(.*?)(?=\\s*[a-dA-D]\\)|Answer:|Explanation:|$)\", block, re.DOTALL))\n",
    "            if not option_matches:\n",
    "                continue\n",
    "\n",
    "            # Question is text before first option\n",
    "            first_option_start = option_matches[0].start()\n",
    "            question_text = block[:first_option_start].strip()\n",
    "            # Remove any trailing Answer/Explanation in question\n",
    "            question_text = re.sub(r\"Answer:.*\", \"\", question_text, flags=re.DOTALL).strip()\n",
    "            question_text = re.sub(r\"Explanation:.*\", \"\", question_text, flags=re.DOTALL).strip()\n",
    "            q_data[\"Question\"] = question_text\n",
    "\n",
    "            # Initialize 4 options\n",
    "            for letter in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "                q_data[f\"Option {letter}\"] = \"\"\n",
    "\n",
    "            # Fill in options A–D\n",
    "            for match in option_matches[:4]:\n",
    "                letter = match.group(1).upper()\n",
    "                option_text = match.group(2).strip()\n",
    "                # Remove any [correct]/[incorrect] tags and Explanation\n",
    "                option_text = re.sub(r\"\\[.*?\\]\", \"\", option_text).strip()\n",
    "                option_text = re.sub(r\"Explanation:.*$\", \"\", option_text).strip()\n",
    "                q_data[f\"Option {letter}\"] = option_text\n",
    "\n",
    "        elif qtype == \"truefalse\":\n",
    "            q_match = re.match(r\"^(.*?)Answer:\", block, re.DOTALL)\n",
    "            q_data[\"Question\"] = q_match.group(1).strip() if q_match else block\n",
    "            q_data[\"Option A\"] = \"True\"\n",
    "            q_data[\"Option B\"] = \"False\"\n",
    "\n",
    "        elif qtype == \"fill\":\n",
    "            q_match = re.match(r\"^(.*?)Answer:\", block, re.DOTALL)\n",
    "            q_data[\"Question\"] = q_match.group(1).strip() if q_match else block\n",
    "            ans_match = re.search(r\"Answer:\\s*(.*)\", block)\n",
    "            q_data[\"Answer\"] = ans_match.group(1).strip() if ans_match else \"\"\n",
    "\n",
    "        elif qtype == \"subjective\":\n",
    "            q_match = re.match(r\"^(.*?)Ideal Answer:\", block, re.DOTALL)\n",
    "            q_data[\"Question\"] = q_match.group(1).strip() if q_match else block\n",
    "            ans_match = re.search(r\"Ideal Answer:\\s*(.*)\", block)\n",
    "            q_data[\"Ideal Answer\"] = ans_match.group(1).strip() if ans_match else \"\"\n",
    "\n",
    "        questions.append(q_data)\n",
    "\n",
    "    if not questions:\n",
    "        return None\n",
    "\n",
    "    # Define explicit columns for MCQs\n",
    "    if qtype in [\"single\", \"multi\"]:\n",
    "        columns = [\"Type\", \"Question\", \"Option A\", \"Option B\", \"Option C\", \"Option D\"]\n",
    "    elif qtype == \"truefalse\":\n",
    "        columns = [\"Type\", \"Question\", \"Option A\", \"Option B\"]\n",
    "    elif qtype == \"fill\":\n",
    "        columns = [\"Type\", \"Question\", \"Answer\"]\n",
    "    elif qtype == \"subjective\":\n",
    "        columns = [\"Type\", \"Question\", \"Ideal Answer\"]\n",
    "    else:\n",
    "        columns = None\n",
    "\n",
    "    df = pd.DataFrame(questions)\n",
    "    if columns:\n",
    "        df = df.reindex(columns=columns)\n",
    "\n",
    "    # Default to XLSX if format invalid\n",
    "    if not fmt or fmt.lower() not in [\"xlsx\", \"csv\", \"json\"]:\n",
    "        fmt = \"xlsx\"\n",
    "\n",
    "    filename = f\"questions_{qtype}.{fmt.lower()}\"\n",
    "\n",
    "    if fmt.lower() == \"xlsx\":\n",
    "        df.to_excel(filename, index=False)\n",
    "    elif fmt.lower() == \"csv\":\n",
    "        df.to_csv(filename, index=False)\n",
    "    elif fmt.lower() == \"json\":\n",
    "        df.to_json(filename, orient=\"records\", indent=4)\n",
    "\n",
    "    return os.path.abspath(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3a15392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_questions(pasted_text, uploaded_file, n=3, level=\"Easy\", download_format=\"xlsx\", qtype=\"single\"):\n",
    "    \n",
    "    content = pasted_text or \"\"\n",
    "    if uploaded_file is not None:\n",
    "        file_text = extract_file(uploaded_file)\n",
    "        if \"Unsupported\" in file_text or \"Error\" in file_text:\n",
    "            return file_text, None\n",
    "        content += \"\\n\" + file_text\n",
    "\n",
    "    if not content.strip():\n",
    "        return \"Please provide text or upload a file.\", None\n",
    "\n",
    "    \n",
    "    generators = {\n",
    "        \"single\": generate_single_choice,\n",
    "        \"multi\": generate_multi_choice,\n",
    "        \"truefalse\": generate_true_false,\n",
    "        \"fill\": generate_fill_blanks,\n",
    "        \"subjective\": generate_subjective\n",
    "    }\n",
    "\n",
    "    if qtype not in generators:\n",
    "        return \"Invalid question type selected.\", None\n",
    "\n",
    "    mcq_text = generators[qtype](content, n, level)\n",
    "    if not mcq_text.strip():\n",
    "        return \"No questions generated. Please try again.\", None\n",
    "\n",
    "    \n",
    "    file_path = save_questions_clean(mcq_text, qtype, download_format)\n",
    "\n",
    "    \n",
    "    return mcq_text.replace(\"\\n\", \"<br>\"), file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c3a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 403, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 60, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\fastapi\\applications.py\", line 1133, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\starlette\\applications.py\", line 113, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\gradio\\brotli_middleware.py\", line 74, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\gradio\\route_utils.py\", line 882, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 63, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\fastapi\\middleware\\asyncexitstack.py\", line 18, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\starlette\\routing.py\", line 716, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\starlette\\routing.py\", line 736, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\starlette\\routing.py\", line 290, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\fastapi\\routing.py\", line 123, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    raise exc\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\starlette\\_exception_handler.py\", line 42, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\fastapi\\routing.py\", line 109, in app\n",
      "    response = await f(request)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\fastapi\\routing.py\", line 389, in app\n",
      "    raw_response = await run_endpoint_function(\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\fastapi\\routing.py\", line 288, in run_endpoint_function\n",
      "    return await dependant.call(**values)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\gradio\\routes.py\", line 1671, in get_upload_progress\n",
      "    await asyncio.wait_for(\n",
      "  File \"C:\\Users\\anjan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\tasks.py\", line 445, in wait_for\n",
      "    return fut.result()\n",
      "  File \"C:\\Users\\anjan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\futures.py\", line 201, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\anjan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\anjan\\OneDrive\\Desktop\\hand_to_text\\.htd\\lib\\site-packages\\gradio\\route_utils.py\", line 528, in is_tracked\n",
      "    return await self._signals[upload_id].wait()\n",
      "  File \"C:\\Users\\anjan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\locks.py\", line 211, in wait\n",
      "    fut = self._get_loop().create_future()\n",
      "  File \"C:\\Users\\anjan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\mixins.py\", line 30, in _get_loop\n",
      "    raise RuntimeError(f'{self!r} is bound to a different event loop')\n",
      "RuntimeError: <asyncio.locks.Event object at 0x000002B3D62FD2D0 [unset]> is bound to a different event loop\n"
     ]
    }
   ],
   "source": [
    "# iface = gr.Interface(\n",
    "#     fn=generate_and_save_mcqs,\n",
    "#     inputs=[\n",
    "#         gr.Textbox(lines=10, placeholder=\"Paste your content here...\"),\n",
    "#         gr.File(label=\"Upload PDF, DOCX, or TXT file\"),\n",
    "#         gr.Number(value=3, precision=0, label=\"Number of MCQs\", interactive=True),\n",
    "#         gr.Dropdown([\"Easy\", \"Intermediate\", \"Hard\"], value=\"Easy\", label=\"Difficulty Level\"),\n",
    "#         gr.Dropdown([\"xlsx\", \"csv\", \"json\"], value=\"xlsx\", label=\"Download Format\")\n",
    "#     ],\n",
    "#     outputs=[\n",
    "#         gr.HTML(label=\"Generated MCQs\"),\n",
    "#         gr.File(label=\"Download File\")\n",
    "#     ],\n",
    "#     title=\" MCQ Generator\",\n",
    "#     description=\"Generate single-choice MCQs from text or files using your local Phi-3 model.\"\n",
    "# )\n",
    "\n",
    "# iface.launch(inline=False, share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e4baed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7874\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=generate_and_save_questions,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=10, placeholder=\"Paste your content here...\"),\n",
    "        gr.File(label=\"Upload PDF, DOCX, or TXT file\"),\n",
    "        gr.Number(value=3, precision=0, label=\"Number of Questions\", interactive=True),\n",
    "        gr.Dropdown([\"Easy\", \"Intermediate\", \"Hard\"], value=\"Easy\", label=\"Difficulty Level\"),\n",
    "        gr.Dropdown([\"xlsx\", \"csv\", \"json\"], value=\"xlsx\", label=\"Download Format\"),\n",
    "        gr.Dropdown([\"single\", \"multi\", \"truefalse\", \"fill\", \"subjective\"], value=\"single\", label=\"Question Type\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.HTML(label=\"Generated Questions\"),\n",
    "        gr.File(label=\"Download File\")\n",
    "    ],\n",
    "    title=\"MCQ / Question Generator\",\n",
    "    description=\"Generate various types of questions from text or files using your local Phi3 model.\"\n",
    ")\n",
    "\n",
    "iface.launch(inline=False, share=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b922bfff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".htd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
